{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import loader\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Africa', 'Asia', 'Europe', 'NorthAmerica', 'SouthAmerica']\n"
     ]
    }
   ],
   "source": [
    "mpl.rcParams['figure.dpi'] = 1000\n",
    "d1 = loader.get_global_case_and_deaths_time_series_data()\n",
    "continent_list = loader.get_available_and_supported_continents()  # In case you want to see continents supported to pass into the call above\n",
    "print(continent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "availableRegions = [\"Africa\", \"Asia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get slices for each country\n",
    "def get_sliced_vectors(country_name, peak_sets, time_series_data, bucket_length):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        country_name (str): exist in both peak_set and time_series_data as an 'Admin0' entry\n",
    "        peak_sets (data frame): the set of all peak data\n",
    "        time_series_data (Tuple): case + death time series data\n",
    "    Returns:\n",
    "        sliced_case: a processed vector of case count\n",
    "        sliced_death: a processed vector of death count\n",
    "    \"\"\"\n",
    "    peak_points = peak_sets.loc[peak_sets['Admin0'] == country_name]\n",
    "    peak_num = np.array([\"X\" in x for x in peak_points.columns]).sum()\n",
    "    sliced_case = np.zeros([peak_num])\n",
    "    sliced_death = np.zeros([peak_num])\n",
    "    vectors = (sliced_case, sliced_death)\n",
    "    for df_idx, df in enumerate(time_series_data):\n",
    "        total_days = np.array([\"Day\" in x for x in df.columns]).sum()\n",
    "        groups = []\n",
    "        for bucket in range(peak_num):\n",
    "            # Get the columns for each bucket, which is centered at X_i (a peak)\n",
    "            begin = 0 if peak_points[\"X\" + str(bucket + 1)].item() - bucket_length / 2 <= 0 else peak_points[\"X\" + str(bucket + 1)].item() - int(bucket_length / 2)\n",
    "            end = total_days if peak_points[\"X\" + str(bucket + 1)].item() + bucket_length / 2 >= total_days else peak_points[\"X\" + str(bucket + 1)].item() + int(bucket_length / 2)\n",
    "            groups.append([\"Day \" + str(day) for day in range(begin, end)])\n",
    "        \n",
    "        # Compute the bucket values\n",
    "        for idx in range(peak_num):\n",
    "            vectors[df_idx][idx] = df.loc[df['Admin0']==country][groups[idx]].sum(axis=1)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(v1, v2, type=\"cosine\"):\n",
    "    \"\"\"\n",
    "    Compute similarity between two vectors, v1 and v2\n",
    "    type: str, can be 'cosine', 'euclidean', 'pearsonCorrelation'\n",
    "    \"\"\"\n",
    "    if type == \"cosine\":\n",
    "        return v1.dot(v2)/(np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    if type == \"euclidean\":\n",
    "        return np.linalg.norm(v1 - v2)\n",
    "    if type == \"pearsonCorrelation\":\n",
    "        return np.cov(np.numpy([v1, v2]))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_map = {}\n",
    "for region in availableRegions:\n",
    "    peak_data = loader.get_peak_data(region=region, peak_num=4)\n",
    "    for country in peak_data[\"Admin0\"]:\n",
    "        case_vec, death_vec = get_sliced_vectors(country, peak_data, d1, 40)\n",
    "        data_map[country] = (case_vec, death_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.48402145 0.7899985  0.59416024 0.47056308]\n",
      " [0.48402145 1.         0.80819657 0.61137239 0.80607176]\n",
      " [0.7899985  0.80819657 1.         0.89881528 0.86280884]\n",
      " [0.59416024 0.61137239 0.89881528 1.         0.8584287 ]\n",
      " [0.47056308 0.80607176 0.86280884 0.8584287  1.        ]]\n",
      "[]\n",
      "[[1.         0.61784322 0.85796812 0.98887214 0.44459368 0.72193377\n",
      "  0.61355149]\n",
      " [0.61784322 1.         0.7963605  0.64552607 0.83125235 0.62655184\n",
      "  0.96613718]\n",
      " [0.85796812 0.7963605  1.         0.88986637 0.63787429 0.69674931\n",
      "  0.74595472]\n",
      " [0.98887214 0.64552607 0.88986637 1.         0.46697323 0.70522446\n",
      "  0.63973684]\n",
      " [0.44459368 0.83125235 0.63787429 0.46697323 1.         0.73349986\n",
      "  0.90252391]\n",
      " [0.72193377 0.62655184 0.69674931 0.70522446 0.73349986 1.\n",
      "  0.66715729]\n",
      " [0.61355149 0.96613718 0.74595472 0.63973684 0.90252391 0.66715729\n",
      "  1.        ]]\n",
      "[]\n",
      "[[1.         0.94241743 0.74335055 0.86792156]\n",
      " [0.94241743 1.         0.63481076 0.82861114]\n",
      " [0.74335055 0.63481076 1.         0.6641044 ]\n",
      " [0.86792156 0.82861114 0.6641044  1.        ]]\n",
      "[]\n",
      "[[1.         0.75842878 0.85946102]\n",
      " [0.75842878 1.         0.81477594]\n",
      " [0.85946102 0.81477594 1.        ]]\n",
      "[]\n",
      "[[1.         0.93380705]\n",
      " [0.93380705 1.        ]]\n",
      "[[1.]]\n",
      "[]\n",
      "[]\n",
      "[[1.         0.45272822 0.39994964 0.43169074 0.91350968]\n",
      " [0.45272822 1.         0.41232276 0.37192216 0.76905944]\n",
      " [0.39994964 0.41232276 1.         0.9815822  0.42413081]\n",
      " [0.43169074 0.37192216 0.9815822  1.         0.43328562]\n",
      " [0.91350968 0.76905944 0.42413081 0.43328562 1.        ]]\n",
      "[[1.         0.51824127]\n",
      " [0.51824127 1.        ]]\n",
      "[]\n",
      "[]\n",
      "[[1.         0.9698034  0.76835054 0.6064182  0.75919126]\n",
      " [0.9698034  1.         0.8560952  0.6641044  0.82263802]\n",
      " [0.76835054 0.8560952  1.         0.72439279 0.87357543]\n",
      " [0.6064182  0.6641044  0.72439279 1.         0.87254818]\n",
      " [0.75919126 0.82263802 0.87357543 0.87254818 1.        ]]\n",
      "[]\n",
      "[]\n",
      "[[1.         0.45272822 0.78482381 0.80636855 0.91100753 0.41232276\n",
      "  0.76905944]\n",
      " [0.45272822 1.         0.51273909 0.64177963 0.60205379 0.39994964\n",
      "  0.91350968]\n",
      " [0.78482381 0.51273909 1.         0.86182933 0.8422743  0.70678182\n",
      "  0.69605857]\n",
      " [0.80636855 0.64177963 0.86182933 1.         0.91194554 0.7922599\n",
      "  0.78866105]\n",
      " [0.91100753 0.60205379 0.8422743  0.91194554 1.         0.69674931\n",
      "  0.82748922]\n",
      " [0.41232276 0.39994964 0.70678182 0.7922599  0.69674931 1.\n",
      "  0.42413081]\n",
      " [0.76905944 0.91350968 0.69605857 0.78866105 0.82748922 0.42413081\n",
      "  1.        ]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-54a75edc6032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/neighbor_map/neighbors_world.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbase_country\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Admin0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Country or territory\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mbase_country\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"neighbor list\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                 \u001b[0mlist_of_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Country or territory\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mbase_country\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"neighbor list\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Compute similarity\n",
    "neighbors = pd.read_csv(\"data/neighbor_map/neighbors_world.csv\")\n",
    "for base_country in d1[0][\"Admin0\"]:\n",
    "    if neighbors.loc[neighbors[\"Country or territory\"]==base_country][\"neighbor list\"].tolist() and type(neighbors.loc[neighbors[\"Country or territory\"]==base_country][\"neighbor list\"].tolist()[0]) is str:\n",
    "                list_of_neighbors = neighbors.loc[neighbors[\"Country or territory\"]==base_country][\"neighbor list\"].tolist()[0].split(\",\")\n",
    "    else:\n",
    "        continue\n",
    "    list_of_neighbors.insert(0, base_country)\n",
    "    # Remove the neighbors not in the list and leading white space\n",
    "    actual_list = []\n",
    "    for idx in range(len(list_of_neighbors)):\n",
    "        list_of_neighbors[idx] = list_of_neighbors[idx].lstrip()\n",
    "        if list_of_neighbors[idx] in data_map:\n",
    "            actual_list.append(list_of_neighbors[idx])\n",
    "    list_of_neighbors = actual_list\n",
    "    sim_mat = np.zeros([len(list_of_neighbors), len(list_of_neighbors)])\n",
    "    for country_idx, country in enumerate(list_of_neighbors):\n",
    "        for target_country_idx, target_country in enumerate(list_of_neighbors):\n",
    "            sim_mat[country_idx, target_country_idx] = compute_similarity(data_map[country][0], data_map[target_country][0])\n",
    "    print(sim_mat)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37ab558b34f4aa88a32054effdad723a148f646610f5f21e3ad761be121c4d16"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('covid')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
